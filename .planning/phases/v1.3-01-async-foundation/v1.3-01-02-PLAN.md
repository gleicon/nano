---
phase: v1.3-01
plan: "02"
type: execute
wave: 2
depends_on: ["v1.3-01-01"]
files_modified:
  - src/api/fetch.zig
  - src/runtime/event_loop.zig
autonomous: true

must_haves:
  truths:
    - "fetch('https://example.com') returns a Promise immediately without blocking the event loop"
    - "setTimeout(() => console.log('timer fired'), 100) fires while a fetch is in-flight"
    - "Two concurrent fetch() calls to different hosts both resolve independently"
    - "fetch() request body handles >64KB payloads (BUF-03)"
  artifacts:
    - path: "src/api/fetch.zig"
      provides: "Non-blocking fetchCallback using thread pool + promise resolver"
      contains: "FetchOperation"
    - path: "src/runtime/event_loop.zig"
      provides: "FetchOperation queue and async resolution"
      contains: "fetch_operations"
  key_links:
    - from: "src/api/fetch.zig fetchCallback"
      to: "FetchOperation allocated and queued"
      via: "EventLoop.queueFetchOperation(op)"
      pattern: "queueFetchOperation"
    - from: "src/runtime/event_loop.zig processEventLoop"
      to: "FetchOperation resolution"
      via: "Thread.spawn for I/O, promise resolved via completed_fetches"
      pattern: "completed_fetches"
---

<objective>
Make fetch() non-blocking: return a Promise immediately, perform HTTP I/O on a background thread (Zig std.Thread), and resolve the Promise in the event loop when the thread completes. Two concurrent fetch() calls run in parallel.

Purpose: Current fetch() calls doFetch() synchronously, blocking the V8 isolate. All setTimeout callbacks and other operations freeze during fetch. This blocks ASYNC-01 and ASYNC-02.
Output: Modified fetch.zig with FetchOperation struct + threaded I/O; event_loop.zig extended with fetch operation tracking and resolution.

Note: xev socket API validation is a known blocker (STATE.md). This plan uses std.Thread to spawn a blocking HTTP call off the main thread, leaving the xev event loop free. This is simpler than a full xev socket state machine and avoids the unvalidated xev.Tcp API. If xev.Tcp becomes validated in a future phase, it can replace the thread approach.
</objective>

<execution_context>
@/Users/gleicon/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gleicon/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/v1.3-01-async-foundation/v1.3-01-RESEARCH.md
@.planning/phases/v1.3-01-async-foundation/v1.3-01-01-SUMMARY.md
@src/api/fetch.zig
@src/runtime/event_loop.zig
@src/js.zig
</context>

<tasks>

<task type="auto">
  <name>Task 1: FetchOperation struct and EventLoop fetch queue</name>
  <files>src/runtime/event_loop.zig</files>
  <action>
Extend EventLoop to track in-flight fetch operations and their results.

**Add new types at top of event_loop.zig (after existing imports):**

```zig
/// Result of a completed async fetch (transferred from thread to main loop)
pub const CompletedFetch = struct {
    op_ptr: usize,          // opaque pointer to FetchOperation (avoids circular dep)
    status: u16,
    body: []u8,             // heap-allocated, owned by this struct
    headers_json: []u8,     // JSON string of headers, heap-allocated
    err_msg: ?[]u8,         // non-null if fetch failed
    allocator: std.mem.Allocator,

    pub fn deinit(self: *CompletedFetch) void {
        self.allocator.free(self.body);
        self.allocator.free(self.headers_json);
        if (self.err_msg) |msg| self.allocator.free(msg);
    }
};
```

**Extend EventLoop struct fields:**
```zig
pending_fetch_count: std.atomic.Value(u32),   // number of in-flight fetches
completed_fetches: std.ArrayListUnmanaged(CompletedFetch),
fetch_mutex: std.Thread.Mutex,                // protects completed_fetches
```

**Initialize in EventLoop.init:**
```zig
.pending_fetch_count = std.atomic.Value(u32).init(0),
.completed_fetches = .{},
.fetch_mutex = .{},
```

**Add to EventLoop.deinit:**
```zig
// Drain completed fetches on shutdown
self.completed_fetches.deinit(self.allocator);
```

**Add new method `addCompletedFetch` (called from worker threads):**
```zig
pub fn addCompletedFetch(self: *EventLoop, result: CompletedFetch) void {
    _ = self.pending_fetch_count.fetchSub(1, .release);
    self.fetch_mutex.lock();
    defer self.fetch_mutex.unlock();
    self.completed_fetches.append(self.allocator, result) catch {};
}
```

**Add new method `drainCompletedFetches`:**
```zig
pub fn drainCompletedFetches(self: *EventLoop) []CompletedFetch {
    self.fetch_mutex.lock();
    defer self.fetch_mutex.unlock();
    const items = self.completed_fetches.toOwnedSlice(self.allocator) catch return &.{};
    return items;
}
```

**Add `incrementPendingFetch`:**
```zig
pub fn incrementPendingFetch(self: *EventLoop) void {
    _ = self.pending_fetch_count.fetchAdd(1, .monotonic);
}
```

**Update `hasPendingWork` to include in-flight fetches:**
```zig
pub fn hasPendingWork(self: *EventLoop) bool {
    if (self.pending_fetch_count.load(.acquire) > 0) return true;
    for (self.timers.items) |timer| {
        if (timer.active) return true;
    }
    return false;
}
```
  </action>
  <verify>
`zig build 2>&1 | head -30`

Expected: compiles without errors. No behavior change yet (fetch still blocking).
  </verify>
  <done>EventLoop compiles with CompletedFetch type, completed_fetches list, fetch_mutex, pending_fetch_count, and drainCompletedFetches method.</done>
</task>

<task type="auto">
  <name>Task 2: Async fetchCallback and event loop resolution</name>
  <files>src/api/fetch.zig</files>
  <action>
Rewrite fetchCallback to be non-blocking. Use std.Thread to run HTTP I/O off the main thread. Add BUF-03 heap fallback for request bodies.

**Add to top of fetch.zig (new imports/types):**

```zig
const event_loop_mod = @import("event_loop");  // adjust import path as used in codebase
// NOTE: fetch.zig needs access to EventLoop to queue completions.
// Look at how other files import event_loop — likely via the server module.
// If direct import not possible, use the global pattern: store event_loop_ptr as usize.
```

Check how fetch.zig currently accesses the event loop — it doesn't. The event loop pointer is held in the HTTP server/script runner. To avoid circular dependencies, use an extern pattern:

**Store event loop pointer via module-level var:**
```zig
// Set once at server startup, read by fetchCallback
var global_event_loop_ptr: ?*anyopaque = null;

pub fn setEventLoop(ptr: *anyopaque) void {
    global_event_loop_ptr = ptr;
}
```

**FetchOperation struct (in fetch.zig):**
```zig
pub const FetchOperation = struct {
    // V8 promise resolver — stored as raw handle values (usize) to avoid V8 type across threads
    // We don't touch V8 from the worker thread. Instead, worker signals completion via EventLoop.
    resolver_id: usize,   // unique ID, mapped in a global table
    url: []u8,
    method: []u8,
    body: []u8,
    allocator: std.mem.Allocator,
    event_loop: *anyopaque,  // opaque EventLoop ptr

    pub fn deinit(self: *FetchOperation) void {
        self.allocator.free(self.url);
        self.allocator.free(self.method);
        if (self.body.len > 0) self.allocator.free(self.body);
        self.allocator.destroy(self);
    }
};
```

**Resolver registry (maps usize ID to v8.PromiseResolver):**
Use a simple global mutex-protected ArrayList:
```zig
const ResolverEntry = struct {
    id: usize,
    resolver: v8.PromiseResolver,
    context_handle: usize,  // store context handle as usize (NOT accessed from thread)
    isolate_handle: usize,  // store isolate handle as usize
};
var resolver_list: std.ArrayListUnmanaged(ResolverEntry) = .{};
var resolver_mutex: std.Thread.Mutex = .{};
var next_resolver_id: std.atomic.Value(usize) = std.atomic.Value(usize).init(1);

fn storeResolver(resolver: v8.PromiseResolver, isolate: v8.Isolate, context: v8.Context) usize {
    const id = next_resolver_id.fetchAdd(1, .monotonic);
    resolver_mutex.lock();
    defer resolver_mutex.unlock();
    resolver_list.append(fetch_allocator, .{
        .id = id,
        .resolver = resolver,
        .context_handle = @intFromPtr(context.handle),
        .isolate_handle = @intFromPtr(isolate.handle),
    }) catch {};
    return id;
}

fn takeResolver(id: usize) ?ResolverEntry {
    resolver_mutex.lock();
    defer resolver_mutex.unlock();
    for (resolver_list.items, 0..) |entry, i| {
        if (entry.id == id) {
            const result = entry;
            _ = resolver_list.swapRemove(i);
            return result;
        }
    }
    return null;
}
```

**Rewrite fetchCallback:**
```zig
fn fetchCallback(raw_info: ?*const v8.C_FunctionCallbackInfo) callconv(.c) void {
    const info = v8.FunctionCallbackInfo.initFromV8(raw_info);
    const isolate = info.getIsolate();
    const context = isolate.getCurrentContext();

    if (info.length() < 1) {
        js.throw(isolate, "fetch() requires a URL or Request argument");
        return;
    }

    // Create Promise + Resolver BEFORE spawning thread
    const resolver = v8.PromiseResolver.init(context);
    const promise = resolver.getPromise();

    // Parse URL and method (stack buffers OK here — these are small)
    const url_arg = info.getArg(0);
    var url_buf: [4096]u8 = undefined;
    var url_len: usize = 0;
    var method_buf: [16]u8 = undefined;
    var method_len: usize = 3;
    @memcpy(method_buf[0..3], "GET");

    // BUF-03: heap-allocate body for potentially large payloads
    var body_heap: []u8 = &.{};

    // [URL/method/body parsing — same logic as before, except body:]
    // For body, determine size first, then heap-allocate:
    // In the options object body parsing section:
    //   const body_val = opts_obj.getValue(...);
    //   if body_val is a string:
    //     const b_str = body_val.toString(context)
    //     const body_len = b_str.lenUtf8(isolate)
    //     body_heap = fetch_allocator.alloc(u8, body_len) catch { reject and return; }
    //     _ = b_str.writeUtf8(isolate, body_heap)
    //
    // Keep existing URL/method parsing logic with existing stack buffers (URLs are always <4096)

    // [Copy existing URL/method/body parsing logic here, replacing body with heap alloc]

    const url = url_buf[0..url_len];
    const method = method_buf[0..method_len];

    // Store resolver with unique ID
    const resolver_id = storeResolver(resolver, isolate, context);

    // Allocate FetchOperation from heap (lives until thread completes)
    const op = fetch_allocator.create(FetchOperation) catch {
        _ = takeResolver(resolver_id);  // remove from registry
        _ = resolver.reject(context, v8.String.initUtf8(isolate, "fetch: out of memory").toValue());
        info.getReturnValue().set(v8.Value{ .handle = @ptrCast(promise.handle) });
        return;
    };
    op.* = FetchOperation{
        .resolver_id = resolver_id,
        .url = fetch_allocator.dupe(u8, url) catch {
            fetch_allocator.destroy(op);
            _ = resolver.reject(context, v8.String.initUtf8(isolate, "fetch: out of memory").toValue());
            info.getReturnValue().set(v8.Value{ .handle = @ptrCast(promise.handle) });
            return;
        },
        .method = fetch_allocator.dupe(u8, method) catch { /* cleanup + reject */ return; },
        .body = body_heap,
        .allocator = fetch_allocator,
        .event_loop = global_event_loop_ptr orelse {
            // No event loop — fall back to synchronous (repl/eval mode)
            var result = doFetch(url, method, body_heap) catch |err| {
                var eb: [256]u8 = undefined;
                const msg = std.fmt.bufPrint(&eb, "fetch failed: {s}", .{@errorName(err)}) catch "fetch failed";
                _ = resolver.reject(context, v8.String.initUtf8(isolate, msg).toValue());
                info.getReturnValue().set(v8.Value{ .handle = @ptrCast(promise.handle) });
                fetch_allocator.destroy(op);
                return;
            };
            defer result.deinit();
            const response = createFetchResponse(isolate, context, result.status, result.body, result.headers);
            _ = resolver.resolve(context, v8.Value{ .handle = @ptrCast(response.handle) });
            info.getReturnValue().set(v8.Value{ .handle = @ptrCast(promise.handle) });
            fetch_allocator.destroy(op);
            return;
        },
    };

    // Increment pending count BEFORE spawning thread
    const el = @as(*@import("event_loop").EventLoop, @ptrCast(@alignCast(global_event_loop_ptr.?)));
    el.incrementPendingFetch();

    // Spawn worker thread — thread owns `op`, frees it when done
    const thread = std.Thread.spawn(.{}, fetchWorker, .{op}) catch {
        el.pending_fetch_count.fetchSub(1, .release) catch {};
        _ = takeResolver(resolver_id);
        _ = resolver.reject(context, v8.String.initUtf8(isolate, "fetch: thread spawn failed").toValue());
        op.deinit();
        info.getReturnValue().set(v8.Value{ .handle = @ptrCast(promise.handle) });
        return;
    };
    thread.detach();

    // Return Promise immediately (unresolved)
    info.getReturnValue().set(v8.Value{ .handle = @ptrCast(promise.handle) });
}
```

**fetchWorker (runs on background thread — NO V8 API calls):**
```zig
fn fetchWorker(op: *FetchOperation) void {
    const el = @as(*@import("event_loop").EventLoop, @ptrCast(@alignCast(op.event_loop)));

    var result = doFetch(op.url, op.method, op.body) catch |err| {
        var eb: [256]u8 = undefined;
        const msg = std.fmt.bufPrint(&eb, "fetch failed: {s}", .{@errorName(err)}) catch "fetch failed";
        const err_copy = fetch_allocator.dupe(u8, msg) catch null;
        el.addCompletedFetch(.{
            .op_ptr = @intFromPtr(op),
            .status = 0,
            .body = &.{},
            .headers_json = fetch_allocator.dupe(u8, "{}") catch &.{},
            .err_msg = err_copy,
            .allocator = fetch_allocator,
        });
        op.deinit();
        return;
    };
    defer result.deinit();

    // Serialize headers to simple JSON for transfer (avoids V8 types across threads)
    var hdr_buf: [4096]u8 = undefined;
    var hdr_stream = std.io.fixedBufferStream(&hdr_buf);
    const hw = hdr_stream.writer();
    _ = hw.writeAll("{") catch {};
    for (result.headers, 0..) |h, i| {
        if (i > 0) _ = hw.writeAll(",") catch {};
        _ = hw.print("\"{s}\":\"{s}\"", .{h.name, h.value}) catch {};
    }
    _ = hw.writeAll("}") catch {};
    const hdr_json = hdr_stream.getWritten();
    const hdr_copy = fetch_allocator.dupe(u8, hdr_json) catch fetch_allocator.dupe(u8, "{}") catch &.{};

    const body_copy = fetch_allocator.dupe(u8, result.body) catch &.{};

    el.addCompletedFetch(.{
        .op_ptr = @intFromPtr(op),
        .status = result.status,
        .body = body_copy,
        .headers_json = hdr_copy,
        .err_msg = null,
        .allocator = fetch_allocator,
    });
    op.deinit();
}
```

**Add `resolveCompletedFetches(isolate, context)` called from the script/server event loop after each tick:**
```zig
pub fn resolveCompletedFetches(isolate: v8.Isolate, context: v8.Context, el: *@import("event_loop").EventLoop) void {
    const items = el.drainCompletedFetches();
    defer el.allocator.free(items);

    for (items) |*item| {
        defer item.deinit();

        const entry = takeResolver(item.op_ptr) orelse {
            // resolver already gone (shouldn't happen)
            continue;
        };

        // Enter V8 isolate + context for promise resolution
        isolate.enter();
        defer isolate.exit();
        const scope = v8.HandleScope.init(isolate);
        defer scope.exit();
        context.enter();
        defer context.exit();

        if (item.err_msg) |msg| {
            _ = entry.resolver.reject(context, v8.String.initUtf8(isolate, msg).toValue());
        } else {
            // Parse headers_json back to simple object for createFetchResponse
            // For now, pass empty headers slice (header parsing improvement is optional)
            var header_list: [0]HeaderEntry = .{};
            const response = createFetchResponse(isolate, context, item.status, item.body, &header_list);
            _ = entry.resolver.resolve(context, v8.Value{ .handle = @ptrCast(response.handle) });
        }
    }
}
```

NOTE: `takeResolver` needs to look up by `resolver_id`, not `op_ptr`. Fix: store `resolver_id` in CompletedFetch instead of `op_ptr`, and have `fetchWorker` copy `op.resolver_id` before calling `op.deinit()`.

**Wire up `setEventLoop` and `resolveCompletedFetches` in the server/script runner:**
- Find where `processEventLoop` is called (search for it in `src/runtime/script.zig` or `src/server/`)
- Call `fetch.setEventLoop(event_loop_ptr)` once at startup
- After each `event_loop.tick()`, call `fetch.resolveCompletedFetches(isolate, context, event_loop)`

Search for the integration point: `grep -r "processEventLoop\|event_loop.tick\|loop.run" src/`
  </action>
  <verify>
Build: `rm -rf .zig-cache && zig build 2>&1 | head -50`

Test non-blocking fetch (requires network or mock):
```bash
# Test that setTimeout fires during fetch (fetch to a real slow-ish endpoint)
cat > /tmp/test_async_fetch.js << 'EOF'
let timerFired = false;
setTimeout(() => { timerFired = true; console.log('timer:fired'); }, 10);
fetch('https://httpbin.org/delay/0.5')
  .then(r => r.text())
  .then(body => console.log('fetch:done:timerWasTrue=' + timerFired));
EOF
timeout 10 ./zig-out/bin/nano eval "$(cat /tmp/test_async_fetch.js)"
```
Expected: `timer:fired` prints before or concurrent with `fetch:done:timerWasTrue=true`

Test BUF-03 (large body):
```bash
./zig-out/bin/nano eval "fetch('https://httpbin.org/post', {method:'POST', body:'X'.repeat(100000)}).then(r => r.json()).then(d => console.log('body_len:' + d.data.length));"
```
Expected: `body_len:100000`
  </verify>
  <done>Build succeeds. fetch() returns Promise immediately; setTimeout fires during in-flight fetch; two concurrent fetches resolve independently; 100KB request body is transmitted correctly.</done>
</task>

</tasks>

<verification>
After both tasks complete:
1. `zig build` succeeds
2. fetch() returns a Promise (not a resolved value) — confirmed by `.then()` chaining working
3. Timer fires during fetch in-flight — `timerFired = true` before fetch resolves
4. Two `fetch()` calls to different hosts both complete independently
5. Large request body (100KB) transmitted without truncation
</verification>

<success_criteria>
- ASYNC-01: fetch() returns Promise immediately; setTimeout callbacks fire during in-flight fetch
- ASYNC-02: Two concurrent fetch() calls run in parallel (one does not block the other)
- BUF-03: fetch() request body handles payloads >64KB
- eval/repl mode: fetch() falls back to synchronous execution when no event loop is set
</success_criteria>

<output>
After completion, create `.planning/phases/v1.3-01-async-foundation/v1.3-01-02-SUMMARY.md` with:
- Architecture decisions (thread pool vs xev socket — why thread pool was chosen)
- Files changed and new types introduced
- How to wire setEventLoop and resolveCompletedFetches (integration point found)
- Any compilation issues encountered and how resolved
- Verification results (timer/fetch interleaving test output)
</output>
