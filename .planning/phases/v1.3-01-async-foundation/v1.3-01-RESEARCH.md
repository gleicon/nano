# Phase v1.3-01: Async Foundation - Research

**Researched:** 2026-02-17
**Domain:** Heap buffer management, non-blocking async fetch with Promise integration, WritableStream backpressure
**Confidence:** HIGH

## Summary

Phase v1.3-01 addresses two critical limitations in NANO v1.2: hardcoded stack buffers that truncate data over 4-16KB, and blocking fetch() that serializes network operations. The phase requires three interconnected systems: (1) heap buffer fallback for Blob, fetch bodies, atob/btoa, and console output; (2) async fetch using xev sockets with unresolved Promise returns; (3) WritableStream async sink support with Promise-based backpressure.

The research confirms all three domains are well-supported by NANO's existing infrastructure: Zig allocators, V8 PromiseResolver API, libxev event loop, and xev socket completion callbacks. The main complexity is managing Promise resolver lifetimes across async boundaries and coordinating multiple in-flight operations without blocking the event loop.

**Primary recommendation:** Implement heap buffer fallback first (BUF-01..05) with heap allocators injected into all string/data handlers. This unblocks concurrent work on async fetch (ASYNC-01, ASYNC-02) which requires Promise lifecycle patterns already demonstrated in NANO v1.2 timers. WritableStream async sink (ASYNC-03) builds on fetch's Promise integration once fetch returns unresolved promises.

## Standard Stack

### Core (Already Shipped - v1.2)

| Component | Version/Source | Purpose | In Use |
|-----------|---|---|---|
| **Zig** | 0.14+ | Language for V8 bindings | Yes |
| **V8** | v0.2.4 (lightpanda fork) | JavaScript engine | Yes |
| **libxev** | main branch (2026) | Event loop & socket I/O | Yes |
| **std.heap.ArenaAllocator** | Zig stdlib | Request-scoped memory | Yes (v1.2 scripts) |
| **v8.PromiseResolver** | V8 API | Promise creation & resolution | Yes (timers) |

### Supporting (v1.3 New Requirements)

| Component | Version | Purpose | When to Use |
|-----------|---------|---------|-------------|
| **std.heap.GeneralPurposeAllocator** | Zig stdlib | Fallback for variable-size buffers | Blob >64KB, fetch bodies >8KB, atob/btoa >8KB |
| **xev.Socket** | libxev main | Non-blocking TCP socket ops | Async HTTP requests |
| **xev.Completion** | libxev main | Socket I/O completion tracking | Registering socket callbacks |
| **v8.Persistent<T>** | V8 API | Long-lived handle across GC | Promise resolver lifetime |

### Why These Are Standard

- **V8 PromiseResolver:** Only way to create Promise that resolves asynchronously. Cloudflare workerd, Deno use identical pattern for fetch().
- **xev socket API:** NANO v1.2 already uses xev timers; socket API is sister feature. libxev is designed for both I/O types simultaneously.
- **Zig allocators:** Standard in Zig for flexible memory management. Arena allocator (v1.2) + fallback allocators (v1.3) is the proven pattern.

## Architecture Patterns

### Pattern 1: Heap Buffer Fallback

**What:** String handlers attempt fixed 4-8KB stack buffer first; if content exceeds limit, allocate on heap.

**When to use:** Any JavaScript string/binary operation that:
- Converts between representations (encoding/decoding)
- May receive large inputs (user-provided data)
- Currently has hardcoded buffer size

**Example (from fetch.zig after refactor):**
```zig
// Current: hardcoded [8192]u8 buffer
fn atobCallback(raw_info: ?*const v8.C_FunctionCallbackInfo) callconv(.c) void {
    const ctx = js.CallbackContext.init(raw_info);
    var input_buf: [8192]u8 = undefined;
    const input = js.readString(ctx.isolate, str, &input_buf);
    // If input > 8KB, truncates
}

// Refactored: fallback to heap
fn atobCallback(raw_info: ?*const v8.C_FunctionCallbackInfo) callconv(.c) void {
    const ctx = js.CallbackContext.init(raw_info);

    // Get string length to decide allocation
    const str_len = js.getStringLength(str);

    var stack_buf: [8192]u8 = undefined;
    const input: []u8 = if (str_len <= stack_buf.len) {
        js.readString(ctx.isolate, str, &stack_buf)
    } else {
        // Allocate from heap
        const heap_buf = getAllocator().alloc(u8, str_len) catch {
            js.throw(ctx.isolate, "atob: out of memory");
            return;
        };
        defer getAllocator().free(heap_buf);
        js.readString(ctx.isolate, str, heap_buf)
    };

    // Rest of atob logic works with both stack and heap buffers
}
```

**Why this pattern:** Keeps fast path (common small inputs) on stack; only pays heap allocation cost for rare large inputs. Matches how browsers handle this (e.g., V8 internally).

### Pattern 2: Promise Resolver Lifecycle with Async Operations

**What:** Create Promise immediately, return to caller, resolve when async I/O completes.

**When to use:** fetch(), any future async APIs that don't block event loop.

**Example (from async_fetch_architecture.md research):**
```zig
const FetchOperation = struct {
    resolver_persistent: v8.Persistent(v8.PromiseResolver),
    isolate: v8.Isolate,
    context_persistent: v8.Persistent(v8.Context),

    // xev socket state
    completion: xev.Completion,
    socket: ?std.net.Stream = null,
    state: enum { dns, connect, send, receive_head, receive_body } = .dns,

    allocator: std.mem.Allocator,
};

fn fetchCallback(raw_info: ?*const v8.C_FunctionCallbackInfo) callconv(.c) void {
    const ctx = js.CallbackContext.init(raw_info);

    // Create Promise + Resolver immediately
    const resolver = v8.PromiseResolver.init(ctx.context);
    const promise = resolver.getPromise();

    // Create FetchOperation to track async work
    var op = try allocator.create(FetchOperation);
    op.resolver_persistent = v8.Persistent(v8.PromiseResolver).init(ctx.isolate, resolver);
    op.isolate = ctx.isolate;
    op.context_persistent = v8.Persistent(v8.Context).init(ctx.isolate, ctx.context);

    // Queue socket I/O on event loop (non-blocking)
    event_loop.queueFetchOperation(op);

    // Return Promise IMMEDIATELY (unresolved)
    js.ret(ctx, promise);
}
```

**Why this pattern:** Promise returned before I/O completes. Script continues or runs other timers. When socket data arrives, xev callback re-enters V8 isolate and resolves promise. This is how fetch works in all async JS runtimes.

### Pattern 3: V8 Isolate Entry/Exit for Async Callbacks

**What:** Before calling ANY V8 API from async callback (e.g., xev socket callback), must enter isolate + context. After, exit to allow garbage collection.

**When to use:** Every xev socket callback that touches V8 (create objects, resolve promises).

**Example:**
```zig
fn onSocketReady(
    op_ptr: ?*FetchOperation,
    loop: *xev.Loop,
    completion: *xev.Completion,
    result: xev.Socket.ReadError!usize,
) xev.CallbackAction {
    const op = op_ptr orelse return .disarm;

    const bytes_read = result catch {
        rejectWithError(op, "Socket error");
        return .disarm;
    };

    // CRITICAL: Enter isolate before V8 APIs
    op.isolate.enter();
    defer op.isolate.exit();

    const context = op.context_persistent.get(op.isolate);
    context.enter();
    defer context.exit();

    var scope = v8.HandleScope.init(op.isolate);
    defer scope.exit();

    // NOW safe to call V8 APIs
    const resolver = op.resolver_persistent.get(op.isolate);
    const response = createResponseObject(op.isolate, context, data);
    _ = resolver.resolve(context, response.toValue());

    // Exit happens automatically via defer
    return .disarm;
}
```

**Why critical:** V8 engine is NOT thread-safe. Can only execute one isolate at a time. Entering isolate acquires lock; exiting releases it. Missing enter/exit causes crashes or memory corruption.

### Pattern 4: xev Socket Completion Callback State Machine

**What:** Single callback handles multiple states of socket operation (DNS, connect, send, receive headers, receive body).

**When to use:** fetch() or any socket operation spanning multiple async steps.

**Example:**
```zig
fn onSocketReady(
    op_ptr: ?*FetchOperation,
    loop: *xev.Loop,
    completion: *xev.Completion,
    result: xev.Socket.ReadError!usize,
) xev.CallbackAction {
    const op = op_ptr orelse return .disarm;

    switch (op.state) {
        .dns => {
            // DNS completed, move to connect
            op.state = .connect;
            // Reschedule to wait for socket connect
            return .rearm;
        },
        .connect => {
            // Socket connected, send HTTP request
            op.state = .send;
            const bytes_sent = op.socket.?.writeAll(op.http_request) catch {
                rejectWithError(op, "Write failed");
                return .disarm;
            };
            op.state = .receive_head;
            return .rearm; // Wait for response headers
        },
        .receive_head => {
            // Have headers, check for body
            const header_end = std.mem.indexOf(u8, op.buffer, "\r\n\r\n") orelse {
                return .rearm; // Need more data
            };
            op.state = .receive_body;
            return .rearm;
        },
        .receive_body => {
            // All data received
            const response = parseHttpResponse(op.buffer);
            resolveWithResponse(op, response);
            return .disarm;
        },
    }
}
```

**Why state machine:** Each socket operation is async. Callback re-triggered when socket ready. Must remember where we are in the flow (are we connecting, sending, receiving headers, receiving body?) to know what to do next.

### Anti-Patterns to Avoid

- **Allocating resolver inside allocator that goes out of scope:** PromiseResolver MUST outlive the callback creating it. Use Persistent<PromiseResolver> or arena allocator that spans entire request lifetime.
- **Calling V8 APIs from xev callback without isolate.enter():** Will crash or corrupt memory. Every xev callback that touches V8 needs enter/exit pair.
- **Using stack buffers for user input:** If JS code can pass 10MB string to atob(), will overflow stack. Always check string length and fallback to heap.
- **Freeing FetchOperation before promise resolves:** If promise passed to async code (stored in global), freeing the operation while promise unresolved will crash. Keep operations alive until request end (arena pattern).
- **Not calling `context.enter()`:** Just isolate.enter() is insufficient. Must also enter context to access global object and create values.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Variable-size buffers for strings | Custom buffer manager | Zig std.heap allocators | Allocators handle fragmentation, OOM recovery, reallocation. Rolling custom means bugs. |
| Promise creation and resolution | Manual value casting | v8.PromiseResolver API | V8 handles promise state machine, microtask queuing, GC. Manual approach loses promise semantics. |
| Non-blocking socket I/O | Manual select()/poll() | libxev Socket API | xev abstracts Linux io_uring, macOS kqueue, WASI. Manual polling misses platform optimizations. |
| Tracking in-flight operations | Global state | FetchOperation struct + arena | Global state is hard to reason about, leak-prone. Struct + arena = automatic cleanup. |
| Promise resolver persistence across GC | Store raw v8::Value | v8::Persistent<PromiseResolver> | Raw values are collected by GC. Persistent handles keep refs alive. |

**Key insight:** Async Fetch is fundamentally complex because multiple independently-timed systems (JS execution, socket I/O, garbage collection, Promise state machine) interact. The patterns above (allocators, Persistent handles, state machines, enter/exit protocol) are battle-tested by V8 embeddings like workerd and Deno. Deviating from these patterns introduces subtle races and memory bugs.

## Common Pitfalls

### Pitfall 1: Stack Buffer Overflow on Large Inputs

**What goes wrong:** JavaScript code passes 100KB string to atob(). Code uses fixed `[8192]u8` stack buffer. Only first 8KB read, rest truncated. User sees wrong output or silent data loss.

**Why it happens:** Early NANO code optimized for "normal" cases (small inputs). No length check before reading into fixed buffer.

**How to avoid:**
1. Get string length from V8 before allocating: `const len = str.utf8LengthV2(isolate);`
2. If len > stack_buf.len, allocate heap: `const buf = try allocator.alloc(u8, len);`
3. Test with 50KB+ inputs explicitly

**Warning signs:**
- "atob returns wrong value for large input"
- "Blob.text() truncates at 64KB"
- "console.log of big string is incomplete"

### Pitfall 2: Using Freed Memory in Promise Resolution

**What goes wrong:** FetchOperation allocated in function scope. Function returns. Promise still unresolved. xev socket callback fires, tries to access op->context_persistent. Accessing freed memory = crash.

**Why it happens:** Early versions might allocate FetchOperation on request's arena, then release arena before socket callback. Or allocate from stack.

**How to avoid:**
- Allocate FetchOperation from request-scoped arena allocator (never freed until request ends)
- Use Persistent<> for isolate/context handles
- Add comment at allocation: `// Freed at end of request, not when operation completes`

**Warning signs:**
- "Segfault in fetch callback"
- "Random crashes when fetch completes"
- Memory corruption messages from AddressSanitizer

### Pitfall 3: Holding Isolate Lock While Blocking

**What goes wrong:** fetch() creates Promise and calls `socket.writeAll()` synchronously (blocks for ~100ms). Entire isolate locked. Other timers can't run. Script hangs.

**Why it happens:** Easy to forget that blocking socket call must happen outside isolate. Or using synchronous socket API instead of xev.

**How to avoid:**
- DO NOT call socket.writeAll/read from V8 callback
- Only use xev socket APIs in event loop
- Queue FetchOperation, return Promise, let event loop handle I/O
- Test by running other timers concurrently with fetch

**Warning signs:**
- "fetch() blocks other timers"
- "Two concurrent fetches don't run in parallel"
- CPU usage shows single thread spinning

### Pitfall 4: Not Calling context.enter() Before V8 APIs

**What goes wrong:** Code enters isolate, creates v8::String, accesses global object. All crash because context not entered. V8 doesn't know which context to use for string creation or global lookup.

**Why it happens:** Isolate.enter() is visible in stack trace. context.enter() is easy to forget. Code appears to work for simple cases (reading values) but fails on object creation.

**How to avoid:**
- Always enter BOTH isolate AND context for async callbacks
- Pattern: `isolate.enter(); defer isolate.exit(); context.enter(); defer context.exit();`
- Use helper function: `fn enterContext(isolate, context) { isolate.enter(); context.enter(); }`

**Warning signs:**
- "V8 assertion failure in context"
- "Segfault in GetCurrent()"
- "Cannot find global object"

### Pitfall 5: Async Callback Re-entered Promise State

**What goes wrong:** Promise resolves in socket callback. Script has .then() handlers. Those execute synchronously in callback (still holding isolate lock). If .then() handler calls fetch(), creates new unresolved promise, deadlock or panic.

**Why it happens:** Unclear that promise resolution triggers microtask execution synchronously.

**How to avoid:**
- After resolving promise in xev callback, immediately return and exit isolate
- Microtasks run in next event loop iteration (via processEventLoop), NOT synchronously
- Don't call user code (or code that might call user code) from async callbacks

**Warning signs:**
- "Deadlock during fetch"
- "Double fetch() call hangs one promise"
- Stack trace shows .then() handler inside socket callback

## Code Examples

Verified patterns from official sources and NANO v1.2 implementation:

### Example 1: Heap Buffer Fallback for atob()

**Source:** Current encoding.zig lines 26-60, refactored pattern

```zig
fn atobCallback(raw_info: ?*const v8.C_FunctionCallbackInfo) callconv(.c) void {
    const ctx = js.CallbackContext.init(raw_info);

    if (ctx.argc() < 1) {
        js.throw(ctx.isolate, "atob requires 1 argument");
        return;
    }

    const str = ctx.arg(0).toString(ctx.context) catch {
        js.throw(ctx.isolate, "atob: invalid argument");
        return;
    };

    // GET LENGTH FIRST
    const str_len = str.utf8LengthV2(ctx.isolate);

    // Stack buffer for small inputs
    var stack_buf: [8192]u8 = undefined;

    // Allocate heap if needed
    const input: []u8 = if (str_len <= stack_buf.len) {
        js.readString(ctx.isolate, str, &stack_buf)
    } else {
        const heap_buf = getAllocator().alloc(u8, str_len) catch {
            js.throw(ctx.isolate, "atob: out of memory");
            return;
        };
        defer getAllocator().free(heap_buf);
        js.readString(ctx.isolate, str, heap_buf)
    };

    // Rest of decoding works with input (stack or heap)
    const decoder = std.base64.standard.Decoder;
    const decoded_size = decoder.calcSizeForSlice(input) catch {
        js.throw(ctx.isolate, "atob: invalid base64");
        return;
    };

    // Output buffer also needs fallback
    var output_stack: [8192]u8 = undefined;
    const output: []u8 = if (decoded_size <= output_stack.len) {
        var buf: [8192]u8 = undefined;
        decoder.decode(&buf, input) catch {
            js.throw(ctx.isolate, "atob: invalid base64");
            return;
        };
        buf[0..decoded_size]
    } else {
        const heap_out = getAllocator().alloc(u8, decoded_size) catch {
            js.throw(ctx.isolate, "atob: out of memory");
            return;
        };
        defer getAllocator().free(heap_out);
        decoder.decode(heap_out, input) catch {
            js.throw(ctx.isolate, "atob: invalid base64");
            return;
        };
        heap_out
    };

    js.retString(ctx, output);
}
```

### Example 2: Promise Resolver Lifecycle (fetch pattern)

**Source:** ASYNC_FETCH_ARCHITECTURE.md, section 2

```zig
const FetchOperation = struct {
    // Promise + V8 context
    resolver_persistent: v8.Persistent(v8.PromiseResolver),
    isolate: v8.Isolate,
    context_persistent: v8.Persistent(v8.Context),

    // Request data
    url: []u8,
    method: []u8,
    headers: std.StringHashMap([]u8),

    // Socket state
    completion: xev.Completion = undefined,
    socket: ?std.net.Stream = null,
    state: enum { dns, connect, send, receive_head, receive_body } = .dns,
    buffer: []u8,
    bytes_received: usize = 0,

    // Cleanup
    allocator: std.mem.Allocator,
};

fn fetchCallback(raw_info: ?*const v8.C_FunctionCallbackInfo) callconv(.c) void {
    const ctx = js.CallbackContext.init(raw_info);

    if (ctx.argc() < 1) {
        js.throw(ctx.isolate, "fetch requires a URL");
        return;
    }

    // Parse arguments
    const url_str = ctx.arg(0).toString(ctx.context) catch {
        js.throw(ctx.isolate, "fetch: invalid URL");
        return;
    };
    var url_buf: [4096]u8 = undefined;
    const url = js.readString(ctx.isolate, url_str, &url_buf);

    // CREATE PROMISE + RESOLVER
    const resolver = v8.PromiseResolver.init(ctx.context);
    const promise = resolver.getPromise();

    // CREATE FETCH OPERATION
    var op = ctx.allocator.create(FetchOperation) catch {
        js.throw(ctx.isolate, "fetch: out of memory");
        return;
    };

    // PERSIST RESOLVER (survives callback return)
    op.resolver_persistent = v8.Persistent(v8.PromiseResolver).init(ctx.isolate, resolver);
    op.isolate = ctx.isolate;
    op.context_persistent = v8.Persistent(v8.Context).init(ctx.isolate, ctx.context);
    op.url = ctx.allocator.dupe(u8, url) catch {
        ctx.allocator.destroy(op);
        js.throw(ctx.isolate, "fetch: out of memory");
        return;
    };
    op.method = ctx.allocator.dupe(u8, "GET") catch {
        ctx.allocator.destroy(op);
        js.throw(ctx.isolate, "fetch: out of memory");
        return;
    };
    op.allocator = ctx.allocator;

    // QUEUE ASYNC OPERATION (doesn't block)
    event_loop.queueFetchOperation(op) catch {
        js.throw(ctx.isolate, "fetch: failed to queue");
        op.allocator.destroy(op);
        return;
    };

    // RETURN PROMISE IMMEDIATELY (unresolved)
    js.ret(ctx, promise);
}
```

### Example 3: V8 Isolate Entry Protocol in xev Callback

**Source:** ASYNC_FETCH_ARCHITECTURE.md, section 4

```zig
fn resolveWithResponse(op: *FetchOperation, response_data: ResponseData) void {
    // === ENTER ISOLATE ===
    op.isolate.enter();
    defer op.isolate.exit();

    // === ENTER CONTEXT ===
    const context_handle = op.context_persistent.get(op.isolate);
    context_handle.enter();
    defer context_handle.exit();

    // === CREATE HANDLE SCOPE ===
    var scope = v8.HandleScope.init(op.isolate);
    defer scope.exit();

    // NOW SAFE: All V8 APIs work
    const resolver = op.resolver_persistent.get(op.isolate);

    // Create Response object
    const global = context_handle.getGlobal();
    const response_ctor_val = js.getProp(global, context_handle, op.isolate, "Response") catch {
        rejectWithError(op, "Response not found");
        return;
    };
    const response_ctor = js.asFunction(response_ctor_val);

    // Construct Response with body and status
    var response_args: [2]v8.Value = .{
        js.string(op.isolate, response_data.body).toValue(),
        js.number(op.isolate, response_data.status).toValue(),
    };
    const response_obj = response_ctor.initInstance(context_handle, &response_args) orelse {
        rejectWithError(op, "Failed to create Response");
        return;
    };

    // === RESOLVE PROMISE ===
    _ = resolver.resolve(context_handle, response_obj.toValue());

    // === CLEANUP (automatic via defer, then manual) ===
    op.resolver_persistent.deinit();
    op.context_persistent.deinit();
    op.allocator.destroy(op);
    // Defer exits happen here
}
```

### Example 4: xev Socket Callback State Machine

**Source:** ASYNC_FETCH_ARCHITECTURE.md, section 5

```zig
fn onSocketReady(
    op_ptr: ?*FetchOperation,
    loop: *xev.Loop,
    completion: *xev.Completion,
    result: xev.Socket.ReadError!usize,
) xev.CallbackAction {
    const op = op_ptr orelse return .disarm;

    const bytes_read = result catch |err| {
        // Network error
        rejectWithError(op, "Socket read error");
        return .disarm;
    };

    switch (op.state) {
        .dns => {
            // This state handled in queueFetchOperation
            unreachable;
        },
        .connect => {
            // Socket connected. Send HTTP request.
            const request_line = try std.fmt.allocPrint(
                op.allocator,
                "GET {s} HTTP/1.1\r\nHost: example.com\r\n\r\n",
                .{op.url},
            );
            defer op.allocator.free(request_line);

            _ = op.socket.?.writeAll(request_line) catch {
                rejectWithError(op, "Write failed");
                return .disarm;
            };

            op.state = .receive_head;
            // Wait for response
            return .rearm;
        },
        .receive_head => {
            // Append new data to buffer
            op.bytes_received += bytes_read;

            // Check if we have full headers
            const header_end = std.mem.indexOf(u8, op.buffer[0..op.bytes_received], "\r\n\r\n");
            if (header_end == null) {
                // Need more data
                if (op.bytes_received >= op.buffer.len) {
                    rejectWithError(op, "Headers too large");
                    return .disarm;
                }
                return .rearm; // Read more
            }

            // Parse status line from headers
            const header_text = op.buffer[0..header_end.?];
            var lines = std.mem.splitSequence(u8, header_text, "\r\n");
            const status_line = lines.next() orelse {
                rejectWithError(op, "Invalid response");
                return .disarm;
            };

            var parts = std.mem.splitSequence(u8, status_line, " ");
            _ = parts.next(); // Skip "HTTP/1.1"
            const status_str = parts.next() orelse "500";

            op.state = .receive_body;

            // Continue reading body
            return .rearm;
        },
        .receive_body => {
            // Append body data
            op.bytes_received += bytes_read;

            if (bytes_read == 0) {
                // EOF - all data received
                const response_data = parseHttpResponse(op.buffer[0..op.bytes_received]);
                resolveWithResponse(op, response_data);
                return .disarm;
            }

            // More data expected
            return .rearm;
        },
    }
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Stack buffers only | Stack + heap fallback | v1.3-01 | Supports any input size, no truncation |
| Blocking fetch() | Async fetch() + Promise | v1.3-01 | Concurrent I/O, timers run during fetch |
| WritableStream.write() sync only | WritableStream.write() returns Promise | v1.3-01 | Async sink support, backpressure signals |
| Single global allocator | Per-operation allocators (arena pattern) | v1.2 already | Predictable cleanup, no leaks |

**Deprecated/outdated:**
- **Fixed buffer sizes:** Pre-v1.3 code like `var buf: [4096]u8` should be replaced with heap fallback for any user-input-dependent data. Leave fixed buffers only for internal buffers (e.g., HTTP read buffer).

## Open Questions

1. **Allocator context in js callbacks**
   - What we know: Current code uses global `page_allocator` in fetch.zig. Need per-request allocator.
   - What's unclear: Should allocator be passed to every API function, or stored in isolate user data?
   - Recommendation: Store allocator in v8::External attached to request context. Functions retrieve via context.GetData(). Avoids threading allocator everywhere.

2. **xev Tcp socket API binding**
   - What we know: NANO v1.2 uses xev.Timer successfully. Socket API should be similar.
   - What's unclear: Exact Socket.readAsync/writeAsync signatures for Zig binding
   - Recommendation: Check libxev main branch directly or reference xev.Timer patterns. libxev documented to support socket read/write with same Proactor callback pattern.

3. **Multiple FetchOperation queuing**
   - What we know: Each fetch() creates one FetchOperation. Multiple fetches queue multiple ops.
   - What's unclear: How to track which operation completed when multiple sockets ready simultaneously?
   - Recommendation: Each FetchOperation has unique xev.Completion. Event loop dispatches callbacks per completion. Standard xev pattern.

4. **Promise resolver cleanup timing**
   - What we know: Persistent handles must survive until promise resolves.
   - What's unclear: Can we safely deinit Persistent handles in resolveWithResponse() or must they stay alive longer?
   - Recommendation: Deinit immediately after resolving. Persistent handle keeps promise object alive internally; releasing the handle is safe.

## Sources

### Primary (HIGH confidence)

- **V8 PromiseResolver API:** lightpanda-io/zig-v8-fork v0.2.4 (build.zig.zon) — Promise creation and lifecycle
- **libxev:** mitchellh/libxev main branch (build.zig.zon) — Event loop, Timer already used, Socket API similar pattern
- **NANO v1.2 source code:** `/Users/gleicon/code/zig/nano/src/` — Existing patterns for allocators (event_loop.zig, timers.zig), Promise usage (js.zig retResolvedPromise), arena allocators (main.zig)
- **Zig stdlib allocators:** std.heap.ArenaAllocator, GeneralPurposeAllocator documented in Zig 0.14+ reference

### Secondary (MEDIUM confidence)

- **NANO research documents:** `.planning/research/ASYNC_FETCH_ARCHITECTURE.md` — Detailed fetch async design (verified with v1.2 patterns)
- **V8 String API:** v8::String::WriteUtf8(), Utf8LengthV2() — Documented at v8.github.io/api
- **libxev README:** github.com/mitchellh/libxev — Callback pattern explained

### Tertiary (LOW confidence - marked for validation)

- **WebSearch (Feb 2026):** General V8 buffer allocation and libxev socket API structure — Used to confirm patterns exist, not detailed specs

## Metadata

**Confidence breakdown:**
- **Standard Stack:** HIGH — V8, libxev, Zig allocators all battle-tested. Already used in v1.2.
- **Architecture Patterns:** HIGH — Patterns verified in v1.2 (timers use same Promise/Persistent/enter-exit protocol). Async Fetch architecture documented in project research.
- **Pitfalls:** HIGH — Identified from v1.2 implementation experience (MEMORY.md documents V8 isolate lifecycle bugs caught during v1.2-04/05)

**Research date:** 2026-02-17
**Valid until:** 2026-03-17 (30 days — stable domains, no fast-moving dependencies)

**Validation needed before implementation:**
- [ ] Confirm xev Socket API supports simultaneous read+write completions (for fetch request+response)
- [ ] Test heap allocator with multiple FetchOperations concurrently
- [ ] Verify Persistent<PromiseResolver> deinit timing (ensure promise object stays valid after deinit)
