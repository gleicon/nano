---
phase: v1.2-02
plan: 03
type: execute
wave: 2
depends_on: [v1.2-02-01, v1.2-02-02]
files_modified:
  - src/api/transform_stream.zig
  - src/api/readable_stream.zig
  - src/api/writable_stream.zig
  - src/server/app.zig
  - src/repl.zig
  - src/engine/script.zig
autonomous: true

must_haves:
  truths:
    - "User can create TransformStream with transform callback"
    - "TransformStream has readable and writable properties"
    - "User can pipe ReadableStream to WritableStream via pipeTo()"
    - "User can chain transforms via pipeThrough()"
    - "User can split stream via ReadableStream.tee()"
    - "User can create stream from array via ReadableStream.from()"
    - "User can iterate stream via for await (const chunk of stream)"
    - "TextEncoderStream converts strings to Uint8Array"
    - "TextDecoderStream converts Uint8Array to strings"
    - "Console.log shows transform stream state: TransformStream { readable: ReadableStream, writable: WritableStream }"
  artifacts:
    - path: "src/api/transform_stream.zig"
      provides: "TransformStream, TextEncoderStream, TextDecoderStream classes"
      min_lines: 300
      exports: ["registerTransformStreamAPI"]
    - path: "src/api/readable_stream.zig"
      provides: "pipeTo, pipeThrough, tee, from methods, async iteration"
      contains: "pipeTo|pipeThrough|tee|from|asyncIterator"
    - path: "src/api/writable_stream.zig"
      provides: "Support for pipeTo target"
      contains: "pipeTo"
  key_links:
    - from: "TransformStream"
      to: "ReadableStream + WritableStream"
      via: "readable and writable properties"
      pattern: "readable.*writable"
    - from: "pipeTo()"
      to: "reader.read() + writer.write()"
      via: "transfers chunks between streams"
      pattern: "read.*write"
    - from: "ReadableStream.from()"
      to: "ReadableStream constructor"
      via: "creates stream from iterable"
      pattern: "from.*iterable"
---

<objective>
Implement TransformStream, pipe operations, stream utilities, and text transform streams.

Purpose: Complete the Streams API foundation by adding stream composition (TransformStream), pipe operations (pipeTo/pipeThrough), stream utilities (tee/from/async iteration), and text encoding/decoding streams. This delivers all requirements for Phase v1.2-02.

Output: Fully functional stream ecosystem matching Cloudflare Workers Streams API, ready for HTTP Response integration in v1.2-03.
</objective>

<execution_context>
@/Users/gleicon/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gleicon/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/Users/gleicon/code/zig/nano/.planning/PROJECT.md
@/Users/gleicon/code/zig/nano/.planning/ROADMAP.md
@/Users/gleicon/code/zig/nano/.planning/STATE.md
@/Users/gleicon/code/zig/nano/.planning/phases/v1.2-02-streams-foundation/v1.2-02-CONTEXT.md

## Prior Plan Implementations

This plan builds on:
@/Users/gleicon/code/zig/nano/.planning/phases/v1.2-02-streams-foundation/v1.2-02-01-SUMMARY.md (ReadableStream)
@/Users/gleicon/code/zig/nano/.planning/phases/v1.2-02-streams-foundation/v1.2-02-02-SUMMARY.md (WritableStream)

## Existing API Patterns

Reference these for implementation pattern:
@/Users/gleicon/code/zig/nano/src/js.zig
@/Users/gleicon/code/zig/nano/src/api/request.zig
@/Users/gleicon/code/zig/nano/src/api/encoding.zig (TextEncoder/Decoder pattern)
@/Users/gleicon/code/zig/nano/src/server/app.zig (lines 220-240 for registration pattern)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement TransformStream class</name>
  <files>src/api/transform_stream.zig</files>
  <action>
Create src/api/transform_stream.zig implementing WinterCG-compliant TransformStream API.

**TransformStream class:**
- Constructor accepts transformer object with optional start(controller), transform(chunk, controller), flush(controller) callbacks
- Constructor accepts optional writableStrategy and readableStrategy objects with highWaterMark
- Creates internal ReadableStream and WritableStream pair
- readable property (getter): returns the readable side
- writable property (getter): returns the writable side
- Transform logic: chunks written to writable side → transform callback → enqueued to readable side
- Symbol.toStringTag = 'TransformStream' (for console.log formatting)

**Implementation approach:**
- Use existing ReadableStream and WritableStream constructors (from Plans 01 and 02)
- WritableStream sink.write calls transformer.transform(chunk, controller)
- WritableStream sink.close calls transformer.flush(controller) then readable controller.close()
- TransformStreamDefaultController: wrapper around readable controller with enqueue/error/terminate methods
- Store readable and writable streams in hidden properties: _readable, _writable

**Error handling:**
- Transform callback throw → both streams enter errored state
- Follow WHATWG spec error semantics from CONTEXT.md

**Pattern notes:**
- Import ReadableStream and WritableStream from separate files
- Use existing stream constructors, not duplicate code
- Register with js.addGlobalClass() like other APIs
  </action>
  <verify>
zig build
./zig-out/bin/nano --repl
# Test in REPL:
const transform = new TransformStream({
  transform(chunk, controller) {
    controller.enqueue(chunk.toUpperCase());
  }
});
const writer = transform.writable.getWriter();
const reader = transform.readable.getReader();
writer.write("hello");
reader.read().then(result => console.log(result));
# Expect: {value: "HELLO", done: false}

# Test console.log formatting:
console.log(transform);
# Expect: TransformStream { readable: ReadableStream, writable: WritableStream }
  </verify>
  <done>
- TransformStream constructor creates readable/writable pair
- Transform callback receives chunks from writable, enqueues to readable
- Flush callback called on close
- Both sides accessible via readable/writable properties
- Symbol.toStringTag provides readable console output
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement TextEncoderStream and TextDecoderStream</name>
  <files>src/api/transform_stream.zig</files>
  <action>
Add TextEncoderStream and TextDecoderStream as TransformStream implementations in transform_stream.zig.

**TextEncoderStream class:**
- Constructor takes no arguments
- Extends TransformStream with transformer that converts strings to Uint8Array
- Transform callback: converts string chunk to UTF-8 Uint8Array using TextEncoder logic
- Use existing TextEncoder implementation from encoding.zig as reference
- Create Uint8Array in V8 for encoded bytes
- Symbol.toStringTag = 'TextEncoderStream' (for console.log formatting)

**TextDecoderStream class:**
- Constructor accepts optional encoding (default: "utf-8") and options
- Extends TransformStream with transformer that converts Uint8Array to strings
- Transform callback: converts Uint8Array chunk to UTF-8 string using TextDecoder logic
- Use existing TextDecoder implementation from encoding.zig as reference
- Handle partial multi-byte sequences at chunk boundaries (buffer incomplete bytes)
- Symbol.toStringTag = 'TextDecoderStream' (for console.log formatting)

**Implementation notes:**
- Both are convenience constructors wrapping TransformStream
- TextEncoderStream constructor creates TransformStream with encoding transform
- TextDecoderStream constructor creates TransformStream with decoding transform
- Follow pattern from encoding.zig for actual encoding/decoding logic
- Store partial byte buffer in controller for TextDecoderStream multi-byte handling

**Pattern notes:**
- Register both classes with js.addGlobalClass()
- Reference encoding.zig for TextEncoder/TextDecoder byte conversion logic
- Handle Uint8Array creation via V8 ArrayBuffer API
  </action>
  <verify>
zig build
./zig-out/bin/nano --repl
# Test TextEncoderStream:
const encoder = new TextEncoderStream();
const writer = encoder.writable.getWriter();
const reader = encoder.readable.getReader();
writer.write("hello");
reader.read().then(result => console.log(result));
# Expect: {value: Uint8Array[...], done: false}

# Test TextDecoderStream:
const decoder = new TextDecoderStream();
const dWriter = decoder.writable.getWriter();
const dReader = decoder.readable.getReader();
dWriter.write(new Uint8Array([72, 101, 108, 108, 111])); // "Hello"
dReader.read().then(result => console.log(result));
# Expect: {value: "Hello", done: false}
  </verify>
  <done>
- TextEncoderStream converts string chunks to Uint8Array
- TextDecoderStream converts Uint8Array chunks to strings
- Both registered as globals
- Multi-byte UTF-8 sequences handled correctly at boundaries
- Symbol.toStringTag provides readable console output for both
  </done>
</task>

<task type="auto">
  <name>Task 3: Add pipeTo and pipeThrough methods to ReadableStream</name>
  <files>src/api/readable_stream.zig</files>
  <action>
Add pipeTo() and pipeThrough() methods to ReadableStream prototype in readable_stream.zig.

**ReadableStream.prototype.pipeTo(destination, options):**
- destination: WritableStream
- options: { preventClose, preventAbort, preventCancel, signal } (all optional, default false)
- Returns: Promise that resolves when piping completes
- Algorithm:
  1. Lock both streams (get reader and writer)
  2. Read from source, write to destination in loop
  3. Handle backpressure via writer.ready
  4. On source close: close destination (unless preventClose)
  5. On source error: abort destination (unless preventAbort)
  6. On destination error: cancel source (unless preventCancel)
  7. Handle AbortSignal if provided
  8. Release locks on completion/error

**ReadableStream.prototype.pipeThrough(transform, options):**
- transform: { readable, writable } (TransformStream or object with both properties)
- options: same as pipeTo (passed through)
- Returns: transform.readable (for chaining)
- Algorithm:
  1. Call this.pipeTo(transform.writable, options)
  2. Return transform.readable (allows chaining)

**Implementation notes:**
- Use V8 Promise API for async operations
- Store pipe state in hidden properties during operation
- Handle all error cases from CONTEXT.md (preventAbort, preventCancel, preventClose)
- Respect abort signal for cancellation

**Error handling:**
- Locked stream throws TypeError
- Invalid destination/transform throws TypeError
- Follow WHATWG pipe semantics from CONTEXT.md
  </action>
  <verify>
zig build
./zig-out/bin/nano --repl
# Test pipeTo:
const readable = new ReadableStream({
  start(controller) {
    controller.enqueue("hello");
    controller.close();
  }
});
const chunks = [];
const writable = new WritableStream({
  write(chunk) { chunks.push(chunk); }
});
readable.pipeTo(writable).then(() => console.log(chunks));
# Expect: ["hello"]

# Test pipeThrough:
const source = new ReadableStream({
  start(controller) {
    controller.enqueue("hello");
    controller.close();
  }
});
const transform = new TransformStream({
  transform(chunk, controller) {
    controller.enqueue(chunk.toUpperCase());
  }
});
const reader = source.pipeThrough(transform).getReader();
reader.read().then(result => console.log(result));
# Expect: {value: "HELLO", done: false}
  </verify>
  <done>
- pipeTo() transfers chunks from readable to writable
- Backpressure handled via writer.ready
- Error propagation respects preventAbort/preventCancel/preventClose
- pipeThrough() chains transforms correctly
  </done>
</task>

<task type="auto">
  <name>Task 4: Add tee, from, and async iteration to ReadableStream</name>
  <files>src/api/readable_stream.zig</files>
  <action>
Add tee(), from(), and Symbol.asyncIterator support to ReadableStream in readable_stream.zig.

**ReadableStream.prototype.tee():**
- Returns: [branch1, branch2] array of two ReadableStream instances
- Algorithm:
  1. Lock original stream (get reader)
  2. Create two new ReadableStream instances with shared queue
  3. Read from original, enqueue to both branches
  4. Close both branches when original closes
  5. Error both branches if original errors
- Implementation: use hidden _teeState property to track branches

**ReadableStream.from(iterable):**
- Static method on ReadableStream constructor
- iterable: Array, generator, async iterable, or iterable with [Symbol.iterator]
- Returns: new ReadableStream
- Algorithm:
  1. Create ReadableStream with pull callback
  2. Pull callback: iterate iterable, enqueue next value
  3. Close stream when iteration complete
  4. Support async iterables (await next() calls)
- Implementation: store iterator in stream state, advance on pull

**Symbol.asyncIterator support:**
- Add [Symbol.asyncIterator]() method to ReadableStream prototype
- Returns: async iterator with next() method
- Algorithm:
  1. Get reader (lock stream)
  2. next() calls reader.read(), returns {value, done}
  3. Release lock when iteration ends (return or throw)
- Enables: `for await (const chunk of stream) { ... }`

**Implementation notes:**
- tee() creates two streams that share the same underlying reader
- from() handles sync and async iterables
- Symbol.asyncIterator uses reader internally
- All methods respect stream locked state

**Error handling:**
- tee() on locked stream throws TypeError
- from() with invalid iterable throws TypeError
- Async iterator releases lock on error
  </action>
  <verify>
zig build
./zig-out/bin/nano --repl
# Test tee:
const original = new ReadableStream({
  start(controller) {
    controller.enqueue("a");
    controller.enqueue("b");
    controller.close();
  }
});
const [branch1, branch2] = original.tee();
const r1 = branch1.getReader();
const r2 = branch2.getReader();
r1.read().then(result => console.log("branch1:", result));
r2.read().then(result => console.log("branch2:", result));
# Expect: both branches receive same chunks

# Test from:
const stream = ReadableStream.from(["a", "b", "c"]);
const reader = stream.getReader();
reader.read().then(result => console.log(result));
# Expect: {value: "a", done: false}

# Test async iteration (requires async context):
const stream = new ReadableStream({
  start(controller) {
    controller.enqueue("x");
    controller.enqueue("y");
    controller.close();
  }
});
(async () => {
  for await (const chunk of stream) {
    console.log(chunk);
  }
})();
# Expect: "x", "y" logged
  </verify>
  <done>
- tee() creates two independent branches receiving same data
- from() creates stream from arrays and iterables
- Async iteration works with for-await-of syntax
- All methods handle locked streams correctly
  </done>
</task>

<task type="auto">
  <name>Task 5: Register TransformStream API and create comprehensive integration tests</name>
  <files>src/server/app.zig, src/repl.zig, src/engine/script.zig, test/streams/integration/index.js, test/streams/integration/nano.json</files>
  <action>
**Part A: Register TransformStream API**

Register in all three runtime initialization locations (after WritableStream):

**src/server/app.zig:**
```zig
const transform_stream = @import("transform_stream");
// ... after writable_stream.registerWritableStreamAPI:
transform_stream.registerTransformStreamAPI(isolate, context);
```

**src/repl.zig:**
```zig
const transform_stream = @import("transform_stream");
// ... after writable_stream.registerWritableStreamAPI:
transform_stream.registerTransformStreamAPI(isolate, context);
```

**src/engine/script.zig:**
```zig
const transform_stream = @import("transform_stream");
// ... after writable_stream.registerWritableStreamAPI:
transform_stream.registerTransformStreamAPI(isolate, context);
```

**Part B: Create integration test app**

**test/streams/integration/nano.json:**
```json
{
  "port": 8080,
  "apps": [
    {
      "hostname": "streams.local",
      "path": "test/apps/streams-integration"
    }
  ]
}
```

**test/apps/streams-integration/index.js:**
```javascript
export default {
  async fetch(request) {
    const url = new URL(request.url());

    // Test 1: Transform stream pipeline
    if (url.pathname === "/transform") {
      const source = new ReadableStream({
        start(controller) {
          controller.enqueue("hello");
          controller.enqueue("world");
          controller.close();
        }
      });

      const upperTransform = new TransformStream({
        transform(chunk, controller) {
          controller.enqueue(chunk.toUpperCase());
        }
      });

      const chunks = [];
      const destination = new WritableStream({
        write(chunk) { chunks.push(chunk); }
      });

      await source.pipeThrough(upperTransform).pipeTo(destination);
      return new Response(JSON.stringify(chunks));
    }

    // Test 2: Tee operation
    if (url.pathname === "/tee") {
      const source = new ReadableStream({
        start(controller) {
          controller.enqueue("a");
          controller.enqueue("b");
          controller.close();
        }
      });

      const [branch1, branch2] = source.tee();

      const results1 = [];
      const results2 = [];

      await branch1.pipeTo(new WritableStream({
        write(chunk) { results1.push(chunk); }
      }));

      await branch2.pipeTo(new WritableStream({
        write(chunk) { results2.push(chunk); }
      }));

      return new Response(JSON.stringify({ branch1: results1, branch2: results2 }));
    }

    // Test 3: ReadableStream.from()
    if (url.pathname === "/from") {
      const stream = ReadableStream.from([1, 2, 3, 4, 5]);
      const chunks = [];
      await stream.pipeTo(new WritableStream({
        write(chunk) { chunks.push(chunk); }
      }));
      return new Response(JSON.stringify(chunks));
    }

    // Test 4: Async iteration
    if (url.pathname === "/async-iter") {
      const stream = new ReadableStream({
        start(controller) {
          controller.enqueue("x");
          controller.enqueue("y");
          controller.enqueue("z");
          controller.close();
        }
      });

      const chunks = [];
      for await (const chunk of stream) {
        chunks.push(chunk);
      }

      return new Response(JSON.stringify(chunks));
    }

    // Test 5: TextEncoderStream + TextDecoderStream
    if (url.pathname === "/text-streams") {
      const source = new ReadableStream({
        start(controller) {
          controller.enqueue("Hello");
          controller.enqueue("World");
          controller.close();
        }
      });

      // Encode to bytes
      const encoder = new TextEncoderStream();
      const decoder = new TextDecoderStream();

      // Pipeline: string -> bytes -> string
      const result = source.pipeThrough(encoder).pipeThrough(decoder);

      const chunks = [];
      await result.pipeTo(new WritableStream({
        write(chunk) { chunks.push(chunk); }
      }));

      return new Response(JSON.stringify(chunks));
    }

    // Test 6: Backpressure through pipeline
    if (url.pathname === "/backpressure") {
      let pullCount = 0;
      const source = new ReadableStream({
        pull(controller) {
          pullCount++;
          if (pullCount <= 5) {
            controller.enqueue(pullCount);
          } else {
            controller.close();
          }
        }
      }, { highWaterMark: 1 });

      const chunks = [];
      await source.pipeTo(new WritableStream({
        write(chunk) { chunks.push(chunk); }
      }, { highWaterMark: 1 }));

      return new Response(JSON.stringify({ chunks, pullCount }));
    }

    // Test 7: Error propagation through pipeline
    if (url.pathname === "/error-propagation") {
      const source = new ReadableStream({
        start(controller) {
          controller.enqueue("ok");
          controller.error(new Error("source error"));
        }
      });

      const transform = new TransformStream({
        transform(chunk, controller) {
          controller.enqueue(chunk);
        }
      });

      try {
        await source.pipeThrough(transform).pipeTo(new WritableStream({
          write(chunk) { /* no-op */ }
        }));
        return new Response("ERROR: should have thrown");
      } catch (e) {
        return new Response(JSON.stringify({ error: "caught" }));
      }
    }

    return new Response("Not Found", { status: 404 });
  }
};
```

Create test/streams/integration/TEST.md:
```markdown
# Streams Integration Tests

## Setup
```bash
./zig-out/bin/nano test/streams/integration/nano.json
```

## Tests

1. Transform pipeline: `curl http://streams.local:8080/transform`
   - Expect: `["HELLO","WORLD"]`

2. Tee operation: `curl http://streams.local:8080/tee`
   - Expect: `{"branch1":["a","b"],"branch2":["a","b"]}`

3. ReadableStream.from: `curl http://streams.local:8080/from`
   - Expect: `[1,2,3,4,5]`

4. Async iteration: `curl http://streams.local:8080/async-iter`
   - Expect: `["x","y","z"]`

5. Text streams: `curl http://streams.local:8080/text-streams`
   - Expect: `["Hello","World"]`

6. Backpressure: `curl http://streams.local:8080/backpressure`
   - Expect: `{"chunks":[1,2,3,4,5],"pullCount":5}` (or 6, depending on timing)

7. Error propagation: `curl http://streams.local:8080/error-propagation`
   - Expect: `{"error":"caught"}`

## Requirements Validated

All Phase v1.2-02 requirements (STRM-01 through STRM-07) validated by these tests.
```
  </action>
  <verify>
zig build
./zig-out/bin/nano --repl
typeof TransformStream
typeof TextEncoderStream
typeof TextDecoderStream
# All Expect: "function"

./zig-out/bin/nano test/streams/integration/nano.json
# In another terminal, run all 7 tests from TEST.md
# All tests should return expected JSON responses
  </verify>
  <done>
- TransformStream available as global
- TextEncoderStream and TextDecoderStream available as globals
- All 7 integration tests pass
- Transform pipelines work end-to-end
- Tee, from, async iteration functional
- Error propagation through pipelines works
  </done>
</task>

</tasks>

<verification>
## Requirements Coverage

All Phase v1.2-02 requirements validated:
- **STRM-01**: ReadableStream ✓ (Plan 01)
- **STRM-02**: WritableStream ✓ (Plan 02)
- **STRM-03**: ReadableStreamDefaultReader ✓ (Plan 01)
- **STRM-04**: ReadableStreamDefaultController ✓ (Plan 01)
- **STRM-05**: WritableStreamDefaultWriter ✓ (Plan 02)
- **STRM-06**: WritableStreamDefaultController ✓ (Plan 02)
- **STRM-07**: Backpressure ✓ (Plans 01, 02, this plan)

## Additional Features

- TransformStream with transform callback ✓
- pipeTo() with full WHATWG options ✓
- pipeThrough() for chaining ✓
- tee() for stream splitting ✓
- from() for creating from iterables ✓
- Async iteration support ✓
- TextEncoderStream and TextDecoderStream ✓

## Manual Verification

1. Build completes: `zig build`
2. REPL exposes all stream classes: `./zig-out/bin/nano --repl`
3. Integration tests pass (7/7 tests in Task 5)
4. Transform pipelines work end-to-end
5. Error propagation through pipelines correct
</verification>

<success_criteria>
- TransformStream creates readable/writable pair with transform logic
- TextEncoderStream and TextDecoderStream registered and functional
- pipeTo() transfers chunks with backpressure and error handling
- pipeThrough() enables transform chaining
- tee() creates independent stream branches
- from() creates streams from arrays/iterables
- Async iteration via for-await-of works
- Symbol.toStringTag provides readable console output for all stream types
- All 7 integration tests return expected results
- Phase v1.2-02 complete: all STRM-01 through STRM-07 requirements validated
</success_criteria>

<output>
After completion, create `.planning/phases/v1.2-02-streams-foundation/v1.2-02-03-SUMMARY.md`
</output>
